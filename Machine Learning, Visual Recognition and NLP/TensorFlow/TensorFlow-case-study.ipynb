{
 "cells": [
  {
   "attachments": {
    "ibm-cloud.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ibm-cloud.png](attachment:ibm-cloud.png)\n",
    "# CASE STUDY - convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import joblib\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synopsis\n",
    "----------\n",
    "\n",
    "You were hired at AAVAIL to be a member of a data science team that works closely together.  Some of your first projects\n",
    "are meant to help marketing with customer retention and to investigate market specific trends. There are also some\n",
    "projects relating to user comments that are getting off the ground.  However, you will also be working alongside\n",
    "the deep-learning specialists that maintain the core product at AAVAIL---its audio and visual manipulation models.\n",
    "\n",
    "Because the team meets regularly all new data science hires are expected to go through a series deep-learning tutorials\n",
    "to ensure that they can contribute to conversations about the core product.   The first in this series is the following\n",
    "tutorial on CNNs.  You will be guided through the following parts.\n",
    "\n",
    "  1. Environment setup\n",
    "  2. Model scaffolding using Keras\n",
    "  3. Logging and Model serialization\n",
    "  4. Model iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST\n",
    "\n",
    ">One project that the data science team at AAVAIL has been tasked with is ensuring that the video feeds are in fact news video feeds.  There are people that are performing quality assurance on these feeds, but eventually the data science team will need to build a service that samples a number of frames from a video, then identifies objects in the images, flagging for review any feeds that may be different.\n",
    "\n",
    "A solid benchmark dataset for this task is the Fashion MNIST dataset.  \n",
    "\n",
    "* training set - 60,000 images\n",
    "* test set - 10,000 images\n",
    "* images are 28 pixels x 28 pixels\n",
    "* classes: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you wish to work with tensorflow v1 then ask it to emulate version 2 behavior\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "print(tf.__version__)\n",
    "\n",
    "## check hardware availability\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data  \n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() \n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', \n",
    "               'Sneaker', 'Bag', 'Ankle boot']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "## Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "X_train = train_images\n",
    "X_test = test_images\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "Visualize a sample of the images to QA the data set (for instance plot one image of each class). Then, print a summary of the data (for instance, the shape of training set, the shape of the test set, the number of sample per class...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (visualization code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Summarize the data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to understand how the data set is built, especially what are the 3 dimensions of X_train and X_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "In this question you are asked to build a base model. The base model that we want to build is composed of a PCA model followed by a classic machine learning classifier. The PCA takes as input the images that have been flattened and creates a representation of the images with few features (the first n principal components). Then, the classifier will classify the images based on this reduced representation. Following the best practices we will create a sklearn Pipeline and pass this pipeline in a grid search to optimize the hyper parameters. You are free to use the classifier that you think will perform best in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "\n",
    "# First we flatten the images to have a data shape that can be ingested by the PCA model.\n",
    "# Take a moment to understand what does this function (flatten()) do to the images \n",
    "# and why this step is necessary.\n",
    "X_train_flat = np.array([i.flatten() for i in train_images])\n",
    "X_test_flat = np.array([i.flatten() for i in test_images])\n",
    "\n",
    "pca = #<>\n",
    "estimator = #<>\n",
    "\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('clf', estimator)])\n",
    "\n",
    "# Add the hyper-parameters that you want to optimize during your training\n",
    "param_grid = {\n",
    "    #<>\n",
    "}\n",
    "\n",
    "## we create a \"saved\" folder to save the trained model. \n",
    "if not os.path.isdir(\"saved\"):\n",
    "    os.mkdir(\"saved\")\n",
    "\n",
    "saved_model_filename = os.path.join(\"saved\", 'ml-model.joblib')\n",
    "if not os.path.exists(saved_model):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    grid = #<>\n",
    "    grid.fit(#<>)\n",
    "        \n",
    "    print(\"saving the pipeline\")\n",
    "    joblib.dump(grid, saved_model_filename)\n",
    "    print(\"train time\", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "else:\n",
    "    print(\"loading {} from file\".format(saved_model_filename))\n",
    "    grid = joblib.load(saved_model_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "# Evaluate your model using the classification_report() function\n",
    "y_pred = grid.predict(#<>)\n",
    "    \n",
    "print(#<>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 -  model scaffolding using Keras\n",
    "\n",
    "Create a function that returns a model using ``keras.models.Sequential()`` and ensure that you pass ``activation_function`` as an argument.  Instaintiate a version of the model and print the summary.  This function is just meant to return a simple multilayer perceptron network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "In this question you are asked to build a function that created a simple multilayer perceptron network. To build a sequential model we first need to initialize the Sequential object, then we sequentially add the layers of the model to that object using the add() method.\n",
    "\n",
    "If your are not familiar with the Sequential class of Keras take a quick look at this documentation : https://keras.io/api/models/sequential/\n",
    "\n",
    "The following link list all the layers that you can add to a Keras sequential object : https://keras.io/api/layers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "\n",
    "def build_mlp():\n",
    "    \"\"\"\n",
    "    This Function creates a simple Dense (or multilayer perceptron) network.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the Sequential object\n",
    "    model = keras.Sequential()\n",
    "    # add a Flatten layer to the sequence\n",
    "    model.add(#<>)\n",
    "    # add a Dense layer to the sequence\n",
    "    model.add(#<>)\n",
    "    # add the last dense layer to the sequence. Because this is the output layer, \n",
    "    # the output dimension should be equal to the number of class that your want to predict.\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))    \n",
    "\n",
    "    return model\n",
    "\n",
    "model_simple = build_mlp(activation_fn='relu')\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encourage you to modify the structure of the network. You can add new layers, change the number of neurons per layer or add dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 4\n",
    "\n",
    "Create another version of your neural network.  This time you should build a proper CNN.  Remember that one pattern to consider starting from is alternating ``Con2D`` and ``MaxPooling2D`` layers.  This is often followed by a couple of ``Dense`` layers.  Recall that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The output of the last ``Dense`` layer should correspond to the number of classes and generally uses a 'softmax' activation.  Use `model.summary()` to ensure a cohesive architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "\n",
    "def build_cnn():\n",
    "    \"\"\"\n",
    "    This function creates a convolutional neural network (cnn)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the Sequential object\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #Add a CNN2D layer. Because this is the first layer, you have to specify the input shape for this layer.\n",
    "    # (Hint : the input shape is (28, 28, 1) for black and white images of size 28x28)\n",
    "    #<>\n",
    "    #Add a Maxpooling layer\n",
    "    #<>\n",
    "    #Add a CNN2D layer\n",
    "    #<>\n",
    "    #Add a Maxpooling layer\n",
    "    #<>\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation=activation_fn))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model \n",
    "\n",
    "\n",
    "model = build_cnn(activation_fn='relu')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - logging and Model serialization\n",
    "\n",
    "You can use a trained model without having to retrain it.  Your can also continue training a model to pick-up training where you left off.  The `tf.keras.callbacks.ModelCheckpoint` callback allows to continually save the model both during and at the end of training.  For long running models this is ideal in case the training is interrupted.  Otherwise you can \n",
    "used `model.save()` and `model.load()`.  In this part you will create a function that accomplished a few things at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 5\n",
    "\n",
    "In this question you will create a function that intend to :\n",
    "\n",
    "1. save your models so that each iteration only needs to be run once\n",
    "2. save the specifics of your model in a log file \n",
    "\n",
    "  * optimizer \n",
    "  * loss_fn \n",
    "  * test_loss\n",
    "  * test_accuracy\n",
    "  * any notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def train_network(model_name, model, loss_fn, X_train, y_train, X_test, y_test, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    This function compiles, trains and saves the keras model\n",
    "    Input : \n",
    "        - model_name : the name of the model (we will save the model under this name)\n",
    "        - model : The keras Sequential model\n",
    "        - loss_fn : the name of the loss function used to train the model (https://keras.io/api/losses/)\n",
    "        - opitmizer : the name of the optimizer used to train the model (https://keras.io/api/optimizers/)\n",
    "        - X_train : the training data\n",
    "        - y_train : the training labels\n",
    "        - X_test : the test data\n",
    "        - y_test : the test labels\n",
    "    \"\"\"\n",
    "\n",
    "    # First we create a filename for the model joining its name with the \"saved\" directory\n",
    "    save_dir = 'saved'\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    saved_model = os.path.join(save_dir, \"{}.h5\".format(model_name))\n",
    "\n",
    "    ## if the model has not been trained, we compile it, train it and save it\n",
    "    if not os.path.exists(saved_model):\n",
    "        ## compile model using the compile method of the keras.models.Sequential class\n",
    "        #<>\n",
    "        \n",
    "        ## fit the model using the fit method of the keras.models.Sequential class\n",
    "        ## (choose 10 epochs and batch size of 64)\n",
    "        #<>\n",
    "        \n",
    "        # Save the model\n",
    "        model.save(saved_model)\n",
    "\n",
    "        ## evaluate the model \n",
    "        test_loss, test_acc = #<>  \n",
    "        \n",
    "        ## save a log file\n",
    "        log_file = os.path.join(save_dir,\"{}.log\".format(model_name)) \n",
    "        with open(log_file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\"loss_function\", loss_fn])\n",
    "            writer.writerow([\"optimizer\", optimizer])\n",
    "            writer.writerow([\"test_loss\", test_loss])\n",
    "            writer.writerow([\"test_acc\", test_acc])\n",
    "\n",
    "    # if the model has already been trained we load it.\n",
    "    else:\n",
    "        print(\"... loading saved model\")\n",
    "        model = keras.models.load_model(saved_model)\n",
    "                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 - model iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Using the functions that you created in the previous questions build the model and train it on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (build and train a mulitlayer perception classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (build and train a CNN)\n",
    "\n",
    "\n",
    "## For the CNN we have to add a third dimension to each sample image. \n",
    "## This dimension is called channel and is expected by the CNN2D layer. \n",
    "## Here the channel value is 1 because we have black and white images. \n",
    "## We would have to set this value to 3 for colored images.\n",
    "X_train_1 = np.expand_dims(X_train, -1)\n",
    "X_test_1 = np.expand_dims(X_test, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
